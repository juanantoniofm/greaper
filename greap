#!/usr/bin/python

# logcoroutine.py
#
# using co-routines to define consumers for the Apache log data
# http://www.dabeaz.com/generators/logcoroutine.py

import argparse

from lib.helpers import apache_log, field_map, consumer, output, filter_time
from myfilters import add_entry,uno,dos,tres
from lib.broadcast import *
import settings

filters_enabled = { }

command_parser = argparse.ArgumentParser(
        description="get some cool stats from apache logs")

command_parser.add_argument("-v","--verbose", action="store_true",
        help="enable debug output", required=False, default=False)

command_parser.add_argument("-q","--query", dest="query",
        help="select this fields from the log line", required=False)

command_parser.add_argument("-f","--filter", dest="filters",
        help="use custom built filters (available: {0})".format(
                ", ".join(filters_enabled.iterkeys())),
                #[x for x in filters_enabled.iterkeys()]),
        required=False)

command_parser.add_argument("-i","--input", dest="input_file",
        help="Filename to read input from", required=True)

command_parser.add_argument("-g","--grep", dest="grep_regex",
        help="Use the expresion t filter the input", required=False)

command_parser.add_argument("-ng","--ngrep",  action="store_false", default = True,
        help="negative grep. Filter the lines that NOT match the expresion (like grep -v regex)", required=False)

args = vars(command_parser.parse_args()) 



################################################################################

stats = {
        "200" : { "count" : 0},
        }

loglevel = "QUIET"  # the default value is DEBUG untill further development


def define_loglevel():
    """sets a level of detail for the log."""
    global loglevel
    if args["verbose"]:
        loglevel = "DEBUG"


def grepit(line, regex=None):
    """only returns a line if it matches the rexex"""
    if regex is None:
        return line
    else:
        if (regex in line) == args["ngrep"]:
            return line


def read_in_lines(fh = None):
    """read a file line by line
    In a lazy way
    """
    while True:
        line = fh.readline()
        if not line:
            break
        else:
            if not grepit(line, args["grep_regex"] ):
                # check that the line matches with the pre-regex and if not, break
                yield ""
            else:
                output(line, "DEBUG:",loglevel) # print debug info
                yield line
 
################################################################################

@consumer
def get_stats():
    global stats
    while True:
        r = (yield)
        add_entry(r, stats)
        output(stats, "DEBUG:", loglevel)


@consumer
def neilfilter():
    while True:
        r=(yield)
        # Check if the uri is on the interests list
        interesting = ["/integration-opera/services",
                      "/ws/fidelio"]
        if r['request'] in interesting:
            output(r, "DEBUG",loglevel)
            #print r["host"], r["request"]
            output("".join[ filter_time(r['datetime']),r["host"] , r["request"] ])

@consumer
def plain_print():
    while True:
        r=(yield)
        print r

def compose(query, data=None):
    """compose the resulting line of the query ready for output.
    :query: list of params to print from the log line parsed.
    :data:  the dictionary with the parsed line.
    :return: the line to print with the fields in the order specified in query."""
    rl = " "
    for f in query.split(","):
        rl += data[f].__str__() + " "
    return rl




@consumer
def query_print():
    while True:
        r=(yield)
        output(compose(args["query"], r))


################################################################################

output(args.__str__(),"DEBUG",loglevel) # show the params for debug purposes

lines = read_in_lines(open(args["input_file"],"r"))
#lines = read_in_lines(open(settings.logfile,"r")) # based on settings config
log   = apache_log(lines)

broadcast(log, [query_print()])


